{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN1k3nHEOinfpw4AfVBsnVZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Create a dictionary using LLM (for new datasets)\n","\n","### Use LLM to classify keywords from extracted OCR\n","\n","##### 1. Extract keywords from sample masked images (focused on specified image regions)\n","\n","##### 2. Classify using LLM and save to txt file"],"metadata":{"id":"SXbOPP9j1_B7"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KzecVk4kzdsD","executionInfo":{"status":"ok","timestamp":1755094881772,"user_tz":-120,"elapsed":16343,"user":{"displayName":"Olumayowa Onabanjo","userId":"03188874242730545723"}},"outputId":"15cfc4ce-a0d1-4273-c9a7-1061548297b3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Define the target directory\n","target_directory = '/content/drive/MyDrive'\n","\n","# Create the directory if it doesn't exist\n","os.makedirs(target_directory, exist_ok=True)"],"metadata":{"id":"2oAfX8lvzdoi","executionInfo":{"status":"ok","timestamp":1755094881803,"user_tz":-120,"elapsed":22,"user":{"displayName":"Olumayowa Onabanjo","userId":"03188874242730545723"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!apt-get install -y tesseract-ocr\n","%pip install opencv-python-headless\n","%pip install pytesseract\n","%pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"9urK2z6BzhZb","executionInfo":{"status":"ok","timestamp":1755098510278,"user_tz":-120,"elapsed":16542,"user":{"displayName":"Olumayowa Onabanjo","userId":"03188874242730545723"}},"outputId":"39c08b47-0ddb-4b75-eafb-1e3369ea17ff"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","tesseract-ocr is already the newest version (4.1.1-2.1build1).\n","0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n","Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n","Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (25.0)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.3.0)\n","Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.99.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.10.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"]}]},{"cell_type":"code","source":["# Step 1: Verify and download the language data file if necessary\n","!ls /usr/share/tesseract-ocr/4.00/tessdata\n","!wget -P /usr/share/tesseract-ocr/4.00/tessdata https://github.com/tesseract-ocr/tessdata/raw/main/spa.traineddata # replace with dataset main language\n","!wget -P /usr/share/tesseract-ocr/4.00/tessdata https://github.com/tesseract-ocr/tessdata/raw/main/cat.traineddata # replace with dataset secondary language(s)\n","\n","# Step 2: Set the TESSDATA_PREFIX environment variable\n","os.environ['TESSDATA_PREFIX'] = '/usr/share/tesseract-ocr/4.00/tessdata'\n","\n","# Step 3: Verify the installation\n","!tesseract --list-langs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"0zEIKFgezwO8","executionInfo":{"status":"ok","timestamp":1755094921137,"user_tz":-120,"elapsed":2435,"user":{"displayName":"Olumayowa Onabanjo","userId":"03188874242730545723"}},"outputId":"a6c07699-c8b4-41ad-ffe6-516246ee0c90"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["configs  eng.traineddata  osd.traineddata  pdf.ttf  tessconfigs\n","--2025-08-13 14:21:58--  https://github.com/tesseract-ocr/tessdata/raw/main/spa.traineddata\n","Resolving github.com (github.com)... 140.82.116.4\n","Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/spa.traineddata [following]\n","--2025-08-13 14:21:58--  https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/spa.traineddata\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 18256019 (17M) [application/octet-stream]\n","Saving to: ‘/usr/share/tesseract-ocr/4.00/tessdata/spa.traineddata’\n","\n","spa.traineddata     100%[===================>]  17.41M  --.-KB/s    in 0.09s   \n","\n","2025-08-13 14:21:58 (187 MB/s) - ‘/usr/share/tesseract-ocr/4.00/tessdata/spa.traineddata’ saved [18256019/18256019]\n","\n","--2025-08-13 14:21:58--  https://github.com/tesseract-ocr/tessdata/raw/main/cat.traineddata\n","Resolving github.com (github.com)... 140.82.116.4\n","Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/cat.traineddata [following]\n","--2025-08-13 14:21:59--  https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/cat.traineddata\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6502025 (6.2M) [application/octet-stream]\n","Saving to: ‘/usr/share/tesseract-ocr/4.00/tessdata/cat.traineddata’\n","\n","cat.traineddata     100%[===================>]   6.20M  --.-KB/s    in 0.06s   \n","\n","2025-08-13 14:22:00 (105 MB/s) - ‘/usr/share/tesseract-ocr/4.00/tessdata/cat.traineddata’ saved [6502025/6502025]\n","\n","List of available languages (4):\n","cat\n","eng\n","osd\n","spa\n"]}]},{"cell_type":"code","source":["import os\n","import pytesseract\n","from pytesseract import Output\n","from PIL import Image\n","import csv\n","import pandas as pd\n","from openai import OpenAI"],"metadata":{"id":"IBQSM1ql2vru","executionInfo":{"status":"ok","timestamp":1755098521500,"user_tz":-120,"elapsed":2866,"user":{"displayName":"Olumayowa Onabanjo","userId":"03188874242730545723"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"21NzNF-NAdlQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755095405923,"user_tz":-120,"elapsed":68702,"user":{"displayName":"Olumayowa Onabanjo","userId":"03188874242730545723"}},"outputId":"fa9ac0f4-3c69-49e0-e1f9-6f4052298425"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: a_16_page_1.png\n","Processing: a_9_page_1.png\n","Processing: a_14_page_1.png\n","Processing: a_2_page_1.png\n","Processing: a_41_page_1.png\n","OCR processing completed for all images.\n"]}],"source":["# Function to perform OCR with a given PSM mode\n","def perform_ocr(image_path, psm_mode):\n","    custom_config = f'--psm {psm_mode}'\n","    ocr_data = pytesseract.image_to_data(Image.open(image_path), config=custom_config, lang='spa+cat', output_type=Output.DICT)\n","    return ocr_data\n","\n","# Function to clean text by removing excess spaces\n","def clean_text(text):\n","    return ' '.join(text.split())\n","\n","# Function to merge OCR results from different PSM modes and remove duplicates\n","def merge_ocr_results(ocr_data_list):\n","    merged_data = {'text': []}\n","    seen_texts = set()\n","\n","    for ocr_data in ocr_data_list:\n","        for i in range(len(ocr_data['text'])):\n","            cleaned_text = clean_text(ocr_data['text'][i])\n","            if len(cleaned_text) >= 3 and cleaned_text not in seen_texts:\n","                seen_texts.add(cleaned_text)\n","                merged_data['text'].append(cleaned_text)\n","\n","    return merged_data\n","\n","# Function to save OCR data to a CSV file\n","def save_to_csv(ocr_data, csv_filename):\n","    with open(csv_filename, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['text'])\n","        for text in ocr_data['text']:\n","            writer.writerow([text])\n","\n","# Directories\n","image_dir = '/content/drive/MyDrive/ICDAR_workshop/Github_AnonED/mask_applied' # (REPLACE FILE PATH)\n","output_dir = '/content/drive/MyDrive/ICDAR_workshop/Github_AnonED/ocr_outputs' # (REPLACE FILE PATH)\n","\n","# Create output directory if it doesn't exist\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Loop through all image files in the directory\n","for filename in os.listdir(image_dir):\n","    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):\n","        image_path = os.path.join(image_dir, filename)\n","        print(f\"Processing: {filename}\")\n","\n","        # Perform OCR with PSM 3, 5, and 12\n","        ocr_data_psm3 = perform_ocr(image_path, 3)\n","        ocr_data_psm5 = perform_ocr(image_path, 5)\n","        ocr_data_psm12 = perform_ocr(image_path, 12)\n","\n","        # Merge and clean OCR results\n","        merged_ocr_data = merge_ocr_results([ocr_data_psm3, ocr_data_psm5, ocr_data_psm12])\n","\n","        # Save to CSV in the output directory\n","        csv_filename = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_ocr.csv\")\n","        save_to_csv(merged_ocr_data, csv_filename)\n","\n","print(\"OCR processing completed for all images.\")"]},{"cell_type":"code","source":["# Function to combine extracted text\n","\n","# Directory containing CSV files\n","csv_dir = '/content/drive/MyDrive/ICDAR_workshop/Github_AnonED/ocr_outputs'  # Replace with your actual folder path\n","\n","# Set to store unique text entries\n","unique_texts = set()\n","\n","# Loop through all CSV files in the directory\n","for filename in os.listdir(csv_dir):\n","    if filename.endswith('.csv'):\n","        file_path = os.path.join(csv_dir, filename)\n","        try:\n","            df = pd.read_csv(file_path)\n","            if 'text' in df.columns:\n","                for text in df['text'].dropna():\n","                    cleaned_text = str(text).strip()\n","                    if cleaned_text:\n","                        unique_texts.add(cleaned_text)\n","        except Exception as e:\n","            print(f\"Error reading {filename}: {e}\")\n","\n","# Convert to list if needed\n","unique_text_list = list(unique_texts)\n","\n","# Print result\n","print(f\"Found {len(unique_text_list)} unique text entries.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uwS0w23_5LYV","executionInfo":{"status":"ok","timestamp":1755098537240,"user_tz":-120,"elapsed":60,"user":{"displayName":"Olumayowa Onabanjo","userId":"03188874242730545723"}},"outputId":"37444a50-2b45-423d-883c-0b815aa79b62"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 335 unique text entries.\n"]}]},{"cell_type":"code","source":["# Set OpenAI API key\n","client = OpenAI(api_key=\"your-openai-api-key\")\n","\n","# Define a prompt template\n","def generate_prompt(text):\n","    return f\"\"\"\n","You are a highly intelligent assistant tasked with classifying text into two groups: \"title block\" and \"other\".\n","Given the following text in Castilian Spanish, Catalan or Galician, classify it based on the following criteria:\n","A token is classified as \"title block\" if it is:\n","  - a profession or title (e.g., engineer, architect, etc.)\n","  - a title block term (e.g., title, date, scale, etc.)\n","  - a drawing role (preparer, reviewer, sign off, etc.)\n","  - a project descriptor (renovation, upgrade, installation)\n","  - a location descriptor or name of a place (municipality, city, province, etc.) - use Named Entity Recognition\n","  - a name (such as a first name, middle name or surname) - use Named Entity Recognition\n","  - a company name (especially energy distribution companies), contact details (email, phone number, website, link)\n","  - a code number (alphanumeric code greater than 5 characters)\n","  - an acronym of any chapter of the Oficial Colleges of Technical Engineers of Spain (for example, any branch of COGITI)\n","  - a brand name (such as an OEM manufacturer such as Philips, ABB, etc.)\n","  - a date, month or year\n","Otherwise, it is classified as \"other\".\n","There may be minor spelling errors in the OCR text output.\n","\n","Text: {text}\n","\n","Output:\n","\"\"\"\n","\n","# Define the function to call the OpenAI API\n","def classify_text(text):\n","    prompt = generate_prompt(text)\n","    try:\n","        response = client.chat.completions.create(\n","            model=\"gpt-4o-mini\",  # Specify the model\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","                {\"role\": \"user\", \"content\": prompt}\n","            ],\n","            max_tokens=300,\n","            temperature=0  # Deterministic output\n","        )\n","        # Extract response content\n","        result = response.choices[0].message.content.strip()\n","        return result\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","        return None\n","\n","\n","# Convert list to DataFrame\n","df = pd.DataFrame({'text': unique_text_list})\n","\n","# Apply the function to classify text and filter out 'other' category\n","\n","# Apply classification\n","df['Classification'] = df['text'].apply(classify_text)\n","\n","# Filter rows where classification is 'title block'\n","df_tb = df[df['Classification'] == 'title block']\n","\n","# Save the filtered data to a new .txt file (REPLACE FILE PATH)\n","df_tb['text'].to_csv('/content/drive/MyDrive/ICDAR_workshop/Github_AnonED/4o_mini_dict.txt', index=False, header=False)\n","\n","print(\"Text classification completed and filtered data saved to .txt file.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJjcwPGC9v1o","executionInfo":{"status":"ok","timestamp":1755099532228,"user_tz":-120,"elapsed":211963,"user":{"displayName":"Olumayowa Onabanjo","userId":"03188874242730545723"}},"outputId":"4a81ceb8-78f5-4adb-feb2-164265be8438"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Text classification completed and filtered data saved to .txt file.\n"]}]}]}